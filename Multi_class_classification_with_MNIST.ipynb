{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multi-class classification with MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "tX_umRMMsa3z"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mhrecaldeb/mhrecaldeb/blob/main/Multi_class_classification_with_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDlWLbfkJtvu"
      },
      "source": [
        "#@title Copyright 2020 Google LLC. Double-click here for license information.\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "# Yann LeCun and Corinna Cortes hold the copyright of MNIST dataset,\n",
        "# which is a derivative work from original NIST datasets. \n",
        "# MNIST dataset is made available under the terms of the \n",
        "# Creative Commons Attribution-Share Alike 3.0 license."
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TL5y5fY9Jy_x"
      },
      "source": [
        "# Multi-Class Classification\n",
        "\n",
        "This Colab explore multi-class classification problems through the classic MNIST dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuKlphuImFSN"
      },
      "source": [
        "## Learning Objectives:\n",
        "\n",
        "After doing this Colab, you'll know how to do the following:\n",
        "\n",
        "  * Understand the classic MNIST problem.\n",
        "  * Create a deep neural network that performs multi-class classification.\n",
        "  * Tune the deep neural network.\n",
        "\n",
        "This exercise introduces image classification with machine learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxj8yVh4mFl5"
      },
      "source": [
        "## The Dataset\n",
        "  \n",
        "This MNIST dataset contains a lot of examples:\n",
        "\n",
        "* The MNIST training set contains 60,000 examples.\n",
        "* The MNIST test set contains 10,000 examples.\n",
        "\n",
        "Each example contains a pixel map showing how a person wrote a digit. For example, the following images shows how a person wrote the digit `1` and how that digit might be represented in a 14x14 pixel map (after the input data is normalized). \n",
        "\n",
        "![Two images. The first image shows a somewhat fuzzy digit one. The second image shows a 14x14 floating-point array in which most of the cells contain 0 but a few cells contain values between 0.0 and 1.0. The pattern of nonzero values corresponds to the image of the fuzzy digit in the first image.](https://www.tensorflow.org/images/MNIST-Matrix.png)\n",
        "\n",
        "Each example in the MNIST dataset consists of:\n",
        "\n",
        "* A label specified by a [rater](https://developers.google.com/machine-learning/glossary/#rater).  Each label must be an integer from 0 to 9.  For example, in the preceding image, the rater would almost certainly assign the label `1` to the example.\n",
        "* A 28x28 pixel map (or it is 14x14?), where each pixel is an integer between 0 and 255. The pixel values are on a gray scale in which 0 represents white, 255 represents black, and values between 0 and 255 represent various shades of gray.  \n",
        "\n",
        "This is a multi-class classification problem with 10 output classes, one for each digit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tX_umRMMsa3z"
      },
      "source": [
        "## Use the right version of TensorFlow\n",
        "\n",
        "The following hidden code cell ensures that the Colab will run on TensorFlow 2.X."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lM75uNH-sTv2"
      },
      "source": [
        "#@title Run on TensorFlow 2.x\n",
        "%tensorflow_version 2.x\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xchnxAsaKKqO"
      },
      "source": [
        "## Import relevant modules\n",
        "\n",
        "The following hidden code cell imports the necessary code to run the code in the rest of this Colaboratory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n9_cTveKmse"
      },
      "source": [
        "#@title Import relevant modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# The following lines adjust the granularity of reporting. \n",
        "pd.options.display.max_rows = 20\n",
        "pd.options.display.float_format = \"{:.3f}\".format\n",
        "\n",
        "# The following line improves formatting when ouputting NumPy arrays.\n",
        "np.set_printoptions(linewidth = 200)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_TaJhU4KcuY"
      },
      "source": [
        "## Load the dataset\n",
        "\n",
        "`tf.keras` provides a set of convenience functions for loading well-known datasets. Each of these convenience functions does the following:\n",
        "\n",
        "* Loads both the training set and the test set.\n",
        "* Separates each set into features and labels.\n",
        "\n",
        "The relevant convenience function for MNIST is called `mnist.load_data()`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZlvdpyYKx7V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24d6c37d-31bd-44a0-b207-df337d234796"
      },
      "source": [
        "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfQkr3hxJGXU"
      },
      "source": [
        "Notice that `mnist.load_data()` returned four separate values:\n",
        "\n",
        "* `x_train` contains the training set's features.\n",
        "* `y_train` contains the training set's labels.\n",
        "* `x_test` contains the test set's features.\n",
        "* `y_test` contains the test set's labels.\n",
        "\n",
        "**Note:** The MNIST .csv training set is already shuffled."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71vsSUM7pdmu"
      },
      "source": [
        "## View the dataset\n",
        "\n",
        "The .csv file for the California Housing Dataset contains column names (for example, `latitude`, `longitude`, `population`). By contrast, the .csv file for MNIST does not contain column names. Instead of column names, you use ordinal numbers to access different subsets of the MNIST dataset. In fact, it is probably best to think of `x_train` and `x_test` as three-dimensional NumPy arrays:  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoOhpjkeCL8Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa13e7e4-b2df-4a15-f7c9-1389db637ba5"
      },
      "source": [
        "# Output example #2917 of the training set.\n",
        "x_train[2917]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0, 127, 100, 156, 239, 224, 177, 213, 159,  70,  13,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0, 110, 250, 254, 254, 254, 254, 254, 254, 254, 254, 184,  10,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0, 216, 254, 254, 254, 254, 254, 254, 254, 254, 254, 251,  54,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   3, 131, 197,  68, 137, 101,  83,  41,  70, 221, 254, 108,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  58, 254, 216,  11,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 110, 254, 254,  24,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   4,  83, 247, 254, 192,  10,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  37, 124, 254, 254, 250,  47,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 113, 178, 250, 254, 254, 254, 252, 178, 128,  50,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  69, 252, 254, 254, 254, 254, 254, 254, 254, 254, 153,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 141, 252, 254, 241, 241, 254, 247, 252, 254, 254, 153,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  68,  82,   5,   5,  82,  37,  65, 167, 254, 190,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 162, 254, 153,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1, 172, 253,  75,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 102, 254, 152,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  38, 230, 216,  20,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,  71, 222, 254, 142,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  66, 254, 254, 157,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   4,  34,  34,  78, 161, 226, 249, 254, 154,   6,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  96, 184, 254, 254, 254, 254, 254, 249,  93,   5,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNJrJKUwvZMR"
      },
      "source": [
        "Alternatively, you can call `matplotlib.pyplot.imshow` to interpret the preceding numeric array as an image. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siRC8a1hJvmq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "e3528d1f-2b75-4b24-9134-469bd63012ba"
      },
      "source": [
        "# Use false colors to visualize the array.\n",
        "plt.imshow(x_train[2917])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6e75cbf650>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-he9IcihDxb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22de4c63-92e6-4312-b922-a508cf6fc2c4"
      },
      "source": [
        "# Output row #10 of example #2917.\n",
        "x_train[2917][10]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  58, 254, 216,  11,   0,   0,   0,   0,   0,   0,   0,   0], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUEWipalhQ8J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d7c4e3a-b349-454e-a00c-be0ea81178d8"
      },
      "source": [
        "# Output pixel #16 of row #10 of example #2900.\n",
        "x_train[2917][10][16]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "58"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ldP-5z1B2vL"
      },
      "source": [
        "## Task 1: Normalize feature values\n",
        "\n",
        "Complete the following code cell to map each feature value from its current representation (an integer between 0 and 255) to a floating-point value between 0 and 1.0. Store the floating-point values in `x_train_normalized` and `x_test_normalized`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YQljE-wizDw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a569dfc-bc1e-4512-ee1e-248946f72d19"
      },
      "source": [
        "x_train_normalized = x_train/255\n",
        "x_test_normalized = x_test/255 \n",
        "print(x_train_normalized[2900][10]) # Output a normalized row"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.         0.         0.         0.         0.         0.         0.         0.55294118 1.         0.66666667 0.11372549 0.         0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8HC-TDgB1D1"
      },
      "source": [
        "#@title Double-click to see a solution to Task 1. \n",
        "\n",
        "x_train_normalized = x_train / 255.0\n",
        "x_test_normalized = x_test / 255.0\n",
        "print(x_train_normalized[2900][10]) # Output a normalized row"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBWRF6CStuNA"
      },
      "source": [
        "## Define a plotting function\n",
        "\n",
        "The following function plots an accuracy curve:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QF0BFRXTOeR3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f391709a-b771-4bfb-f116-e57124366e02"
      },
      "source": [
        "#@title Define the plotting function\n",
        "def plot_curve(epochs, hist, list_of_metrics):\n",
        "  \"\"\"Plot a curve of one or more classification metrics vs. epoch.\"\"\"  \n",
        "  # list_of_metrics should be one of the names shown in:\n",
        "  # https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#define_the_model_and_metrics  \n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Value\")\n",
        "\n",
        "  for m in list_of_metrics:\n",
        "    x = hist[m]\n",
        "    plt.plot(epochs[1:], x[1:], label=m)\n",
        "\n",
        "  plt.legend()\n",
        "\n",
        "print(\"Loaded the plot_curve function.\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded the plot_curve function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3014ezH3C7jT"
      },
      "source": [
        "## Create a deep neural net model\n",
        "\n",
        "The `create_model` function defines the topography of the deep neural net, specifying the following:\n",
        "\n",
        "* The number of [layers](https://developers.google.com/machine-learning/glossary/#layer) in the deep neural net.\n",
        "* The number of [nodes](https://developers.google.com/machine-learning/glossary/#node) in each layer.\n",
        "* Any [regularization](https://developers.google.com/machine-learning/glossary/#regularization) layers.\n",
        "\n",
        "The `create_model` function also defines the [activation function](https://developers.google.com/machine-learning/glossary/#activation_function) of each layer.  The activation function of the output layer is [softmax](https://developers.google.com/machine-learning/glossary/#softmax), which will yield 10 different outputs for each example. Each of the 10 outputs provides the probability that the input example is a certain digit.\n",
        "\n",
        "**Note:** Unlike several of the recent Colabs, this exercise does not define feature columns or a feature layer.  Instead, the model will train on the NumPy array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pedD5GhlDC-y",
        "cellView": "both"
      },
      "source": [
        "def create_model(my_learning_rate):\n",
        "  \"\"\"Create and compile a deep neural net.\"\"\"\n",
        "  \n",
        "  # All models in this course are sequential.\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  # The features are stored in a two-dimensional 28X28 array. \n",
        "  # Flatten that two-dimensional array into a a one-dimensional \n",
        "  # 784-element array.\n",
        "  model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
        "\n",
        "  # Define the first hidden layer.   \n",
        "  model.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
        "  \n",
        "  # Define a dropout regularization layer. \n",
        "  model.add(tf.keras.layers.Dropout(rate=0.2))\n",
        "\n",
        "  # Define the output layer. The units parameter is set to 10 because\n",
        "  # the model must choose among 10 possible output values (representing\n",
        "  # the digits from 0 to 9, inclusive).\n",
        "  #\n",
        "  # Don't change this layer.\n",
        "  model.add(tf.keras.layers.Dense(units=10, activation='softmax'))     \n",
        "                           \n",
        "  # Construct the layers into a model that TensorFlow can execute.  \n",
        "  # Notice that the loss function for multi-class classification\n",
        "  # is different than the loss function for binary classification.  \n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(lr=my_learning_rate),\n",
        "                loss=\"sparse_categorical_crossentropy\",\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  return model    \n",
        "\n",
        "\n",
        "def train_model(model, train_features, train_label, epochs,\n",
        "                batch_size=None, validation_split=0.1):\n",
        "  \"\"\"Train the model by feeding it data.\"\"\"\n",
        "\n",
        "  history = model.fit(x=train_features, y=train_label, batch_size=batch_size,\n",
        "                      epochs=epochs, shuffle=True, \n",
        "                      validation_split=validation_split)\n",
        " \n",
        "  # To track the progression of training, gather a snapshot\n",
        "  # of the model's metrics at each epoch. \n",
        "  epochs = history.epoch\n",
        "  hist = pd.DataFrame(history.history)\n",
        "\n",
        "  return epochs, hist    "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-IXYVfvM4gD"
      },
      "source": [
        "## Invoke the previous functions\n",
        "\n",
        "Run the following code cell to invoke the preceding functions and actually train the model on the training set. \n",
        "\n",
        "**Note:** Due to several factors (for example, more examples and a more complex neural network) training MNIST might take longer than training the California Housing Dataset. Be patient."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nj3v5EKQFY8s",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "72b04fc9-576c-4df4-be10-c823972208fb"
      },
      "source": [
        "# The following variables are the hyperparameters.\n",
        "learning_rate = 0.003\n",
        "epochs = 50\n",
        "batch_size = 4000\n",
        "validation_split = 0.2\n",
        "\n",
        "# Establish the model's topography.\n",
        "my_model = create_model(learning_rate)\n",
        "\n",
        "# Train the model on the normalized training set.\n",
        "epochs, hist = train_model(my_model, x_train_normalized, y_train, \n",
        "                           epochs, batch_size, validation_split)\n",
        "\n",
        "# Plot a graph of the metric vs. epochs.\n",
        "list_of_metrics_to_plot = ['accuracy']\n",
        "plot_curve(epochs, hist, list_of_metrics_to_plot)\n",
        "\n",
        "# Evaluate against the test set.\n",
        "print(\"\\n Evaluate the new model against the test set:\")\n",
        "my_model.evaluate(x=x_test_normalized, y=y_test, batch_size=batch_size)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 1s 38ms/step - loss: 1.6446 - accuracy: 0.4780 - val_loss: 0.8802 - val_accuracy: 0.8029\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.8270 - accuracy: 0.7559 - val_loss: 0.4840 - val_accuracy: 0.8773\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.5887 - accuracy: 0.8242 - val_loss: 0.3867 - val_accuracy: 0.8993\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.4909 - accuracy: 0.8568 - val_loss: 0.3384 - val_accuracy: 0.9084\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.4408 - accuracy: 0.8718 - val_loss: 0.3097 - val_accuracy: 0.9146\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.4075 - accuracy: 0.8812 - val_loss: 0.2902 - val_accuracy: 0.9187\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.3819 - accuracy: 0.8885 - val_loss: 0.2739 - val_accuracy: 0.9240\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.3636 - accuracy: 0.8943 - val_loss: 0.2632 - val_accuracy: 0.9263\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.3465 - accuracy: 0.8987 - val_loss: 0.2516 - val_accuracy: 0.9293\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.3333 - accuracy: 0.9023 - val_loss: 0.2422 - val_accuracy: 0.9322\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.3214 - accuracy: 0.9048 - val_loss: 0.2335 - val_accuracy: 0.9348\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.3111 - accuracy: 0.9084 - val_loss: 0.2273 - val_accuracy: 0.9362\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2989 - accuracy: 0.9122 - val_loss: 0.2201 - val_accuracy: 0.9376\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2932 - accuracy: 0.9138 - val_loss: 0.2150 - val_accuracy: 0.9396\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.2860 - accuracy: 0.9162 - val_loss: 0.2103 - val_accuracy: 0.9406\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.2795 - accuracy: 0.9175 - val_loss: 0.2042 - val_accuracy: 0.9425\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2732 - accuracy: 0.9200 - val_loss: 0.2021 - val_accuracy: 0.9433\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2667 - accuracy: 0.9203 - val_loss: 0.1971 - val_accuracy: 0.9440\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.2591 - accuracy: 0.9242 - val_loss: 0.1939 - val_accuracy: 0.9452\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2556 - accuracy: 0.9243 - val_loss: 0.1887 - val_accuracy: 0.9463\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.2521 - accuracy: 0.9251 - val_loss: 0.1865 - val_accuracy: 0.9470\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2460 - accuracy: 0.9264 - val_loss: 0.1829 - val_accuracy: 0.9484\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.2411 - accuracy: 0.9272 - val_loss: 0.1806 - val_accuracy: 0.9491\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.2384 - accuracy: 0.9287 - val_loss: 0.1780 - val_accuracy: 0.9498\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2341 - accuracy: 0.9307 - val_loss: 0.1752 - val_accuracy: 0.9506\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.2318 - accuracy: 0.9318 - val_loss: 0.1733 - val_accuracy: 0.9500\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2297 - accuracy: 0.9324 - val_loss: 0.1722 - val_accuracy: 0.9508\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2252 - accuracy: 0.9327 - val_loss: 0.1688 - val_accuracy: 0.9527\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2229 - accuracy: 0.9327 - val_loss: 0.1688 - val_accuracy: 0.9517\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.2221 - accuracy: 0.9341 - val_loss: 0.1667 - val_accuracy: 0.9520\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2165 - accuracy: 0.9348 - val_loss: 0.1633 - val_accuracy: 0.9538\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2127 - accuracy: 0.9360 - val_loss: 0.1628 - val_accuracy: 0.9536\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.2126 - accuracy: 0.9364 - val_loss: 0.1612 - val_accuracy: 0.9538\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2088 - accuracy: 0.9371 - val_loss: 0.1592 - val_accuracy: 0.9546\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2073 - accuracy: 0.9379 - val_loss: 0.1583 - val_accuracy: 0.9549\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2059 - accuracy: 0.9381 - val_loss: 0.1578 - val_accuracy: 0.9551\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.2043 - accuracy: 0.9390 - val_loss: 0.1559 - val_accuracy: 0.9557\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 0.2022 - accuracy: 0.9401 - val_loss: 0.1555 - val_accuracy: 0.9561\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.1985 - accuracy: 0.9409 - val_loss: 0.1539 - val_accuracy: 0.9549\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.1990 - accuracy: 0.9396 - val_loss: 0.1512 - val_accuracy: 0.9565\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.1970 - accuracy: 0.9408 - val_loss: 0.1507 - val_accuracy: 0.9570\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.1917 - accuracy: 0.9419 - val_loss: 0.1493 - val_accuracy: 0.9575\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.1935 - accuracy: 0.9417 - val_loss: 0.1495 - val_accuracy: 0.9573\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.1901 - accuracy: 0.9426 - val_loss: 0.1488 - val_accuracy: 0.9567\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.1902 - accuracy: 0.9435 - val_loss: 0.1480 - val_accuracy: 0.9579\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.1887 - accuracy: 0.9427 - val_loss: 0.1478 - val_accuracy: 0.9572\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.1852 - accuracy: 0.9440 - val_loss: 0.1473 - val_accuracy: 0.9572\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.1853 - accuracy: 0.9427 - val_loss: 0.1454 - val_accuracy: 0.9582\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.1825 - accuracy: 0.9446 - val_loss: 0.1455 - val_accuracy: 0.9582\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.1813 - accuracy: 0.9441 - val_loss: 0.1442 - val_accuracy: 0.9590\n",
            "\n",
            " Evaluate the new model against the test set:\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.1468 - accuracy: 0.9582\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.14675681293010712, 0.9581999778747559]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxV1b3//9cnJ3NIIBMIhDAoKuAAGtHW2161paWD1WoHrFq1Fr7eitdvR7VfW73WtvZ7b79tvde2l7ZOrcr1p9VS61C1em2vE6CAEEApAkkIkAEyz/n8/tg78RgCJJjDSXLez8fjPM7Za++9slaM58Ma9lrm7oiIiAxUUrwLICIiI4sCh4iIDIoCh4iIDIoCh4iIDIoCh4iIDEpyvAtwJBQUFPi0adPiXQwRkRFl9erV1e5e2Dc9poHDzBYCPwMiwK/d/bY+56cCdwKFQC1wibuXh+e6gDfCS3e4+6fC9OnAciAfWA1c6u7tByvHtGnTWLVq1ZDVS0QkEZjZ9v7SY9ZVZWYR4A7gY8Bs4CIzm93nsn8D7nX3k4BbgB9GnWtx97nh61NR6T8CfuLuxwB7gStjVQcREdlfLMc45gNb3H1r2CJYDpzX55rZwF/Cz8/1c/5dzMyAc4CHwqR7gPOHrMQiInJIsQwck4GyqOPyMC3aWuCC8POngWwzyw+P081slZm9bGY9wSEf2OfunQfJU0REYijeg+PfAP7DzC4HXgAqgK7w3FR3rzCzGcBfzOwNoG6gGZvZEmAJQHFx8X7nOzo6KC8vp7W19b3VIEGlp6dTVFRESkpKvIsiIkdYLANHBTAl6rgoTOvl7jsJWxxmNga40N33hecqwvetZvY8MA94GBhnZslhq2O/PKPyXgYsAygpKdlvQa7y8nKys7OZNm0aQQ+YDJS7U1NTQ3l5OdOnT493cUTkCItlV9VKYKaZTTezVGARsCL6AjMrMLOeMtxAMMMKM8s1s7Sea4AzgVIPVmR8DvhMeM9lwB8Op3Ctra3k5+craBwGMyM/P1+tNZEEFbPAEbYIlgJPARuBB919g5ndYmY9s6TOAjab2ZvABOD7YfosYJWZrSUIFLe5e2l47jrga2a2hWDM4zeHW0YFjcOn351I4orpGIe7Pw483iftu1GfH+KdGVLR17wInHiAPLcSzNgSEUloe5va+cumPeyqb6VgTCr5WWnkj0mlYEzwnpkam6/4eA+Oi4iMOh1d3ZTvbaGstpmcjBSm5mUyLjOl35Z6c3sna8vqeG3HXl7bvpeyvc0cd1QOJxeNZV7xOOZMGkt6SqT3+vK9zTxdups/b9jNq9tq6eo+8J5KGSkRViw9k5kTsoe0fgoco1xnZyfJyfrPLDLUurudnXUtbK1q4u3q4LWtpolt1U2U722hs88XenZaMsX5mRTnZVKcn0lLexev7djLxsqG3i//GYVZTMvPYvW2Wv64dicAyUnG8ROzmXVUDqWV9WzYWQ/AzPFjuOofZ/DROUcxc3w2tc3t1DS2UdPYTnVjGzVN7VQ3tFGYnTbkddc3Shydf/75lJWV0drayrXXXsuSJUt48skn+fa3v01XVxcFBQU8++yzNDY2cs0117Bq1SrMjJtuuokLL7yQMWPG0NjYCMBDDz3EY489xt13383ll19Oeno6r7/+OmeeeSaLFi3i2muvpbW1lYyMDO666y6OO+44urq6uO6663jyySdJSkpi8eLFzJkzh9tvv51HH30UgKeffpqf//znPPLII/H8VYnEVF1zBxsq6yjdWc+buxvo6ob0lCTSUyKkJQfv6SlJ1Ld0srW6sTdYtHV29+aRmRphWn4WcyaN5RMnTWRafhbFeZnUt3ayvaaJstpmttc2s3l3A89u3ENKxDh5yji+ctbRnFKcy7zicYzLTO3Nb099K2vL61hTtpe1ZXU8s3E3MwrHcMPHjmfB7AnMKBzzrjpMTs1g8riMI/L7UuAA/uWPGygNo/hQmT0ph5vOnXPQa+68807y8vJoaWnhtNNO47zzzmPx4sW88MILTJ8+ndraWgC+973vMXbsWN54I1i6a+/evYf8+eXl5bz44otEIhHq6+v561//SnJyMs888wzf/va3efjhh1m2bBnbtm1jzZo1JCcnU1tbS25uLl/5yleoqqqisLCQu+66iy996Uvv/RciMkS6u52qxjbKapt7u4Mq61spzsvk5KJxnFQ0lqy0/r/a3J2KfS2U7qxnY2UDG3bWsWFnPRX7WnqvKRiTSmokibbOblo7umjt7O5tEUSSjCm5GcwoHMM/HFPAjMIxTC/I4ujCLAqz0wY8aaS72/EwvwMZn5POgtnpLJg9YeC/nCNEgSOObr/99t5/yZeVlbFs2TI++MEP9j4bkZeXB8AzzzzD8uXLe+/Lzc09ZN6f/exniUSCftG6ujouu+wy3nrrLcyMjo6O3nyvuuqq3q6snp936aWX8rvf/Y4rrriCl156iXvvvXeIaiwyONWNbayvCL7c11fUsXl3A+V7W2iP+pc+wLjMFPY1B3/XSQYzx2czd8o45haPI5JkYaAIXvWtwcITZjC9IIt5xeO45IypzJ6Uw+yJOf127XR0BUEkLTlCavJ7n4yadJCAMRIocMAhWwax8Pzzz/PMM8/w0ksvkZmZyVlnncXcuXPZtGnTgPOI/tdN32cqsrKyej9/5zvf4eyzz+aRRx5h27ZtnHXWWQfN94orruDcc88lPT2dz372sxojkZhyd2qb2tlW08Tb1c1sq25i066gNVBZ987f9dT8TGYdlcOCWRMoysukKDeDKbnBe3pKhNqmdtaW7WNN+HqqdBf/tSpY9SgjJcLxE7M59+RJzJqYw+xJORw3IfuALZO+UiJJpES0fVEPfSPESV1dHbm5uWRmZrJp0yZefvllWltbeeGFF3j77bd7u6ry8vJYsGABd9xxBz/96U+BoKsqNzeXCRMmsHHjRo477jgeeeQRsrP7nzlRV1fH5MnBkl533313b/qCBQv4z//8T84+++zerqq8vDwmTZrEpEmTuPXWW3nmmWdi/ruQ0cXdqWlqZ3tNM9trmthd30ZbZxdtnd20dXT3fm5p76J8bzNbq5toaO3svT+SZEzLz+T06XmcMHkscyaNZfakHMZmHHx5m7ysVM4+fjxnHz++txzba5rpdmdqftZBu4VkcBQ44mThwoX88pe/ZNasWRx33HGcccYZFBYWsmzZMi644AK6u7sZP348Tz/9NDfeeCNXX301J5xwApFIhJtuuokLLriA2267jU9+8pMUFhZSUlLSO1De17e+9S0uu+wybr31Vj7xiU/0pn/5y1/mzTff5KSTTiIlJYXFixezdOlSAC6++GKqqqqYNWvWEfl9yMjR3R0Ehsq6Fnbua6WyroXKulbKapvZVtPMjpommtq79rsvNZJEWnISaSlJpCVHSEtJYvK4DM6fO5lpBVlML8hkWn4WRbmZQ9IdZGZMK8g69IUyaBas4jG6lZSUeN+NnDZu3KgvxYNYunQp8+bN48orD7zdiX6Ho4u7s7s+GFN4u7qJfS3t7GvuoK7lndfe5nZ217XR3vXuMYbU5CSKcjOYmpfJ1PwspuZnMjU/k+K8LCaNSyc9OTLi+/UTkZmtdveSvulqcch+Tj31VLKysvjxj38c76JIjDS3d1Kxt4XNuxt6B55Ld9ZT0/TOZpqRJGNsRgrjMlIYm5lCXlYqMwqymDA2nUljM5g4Np1J44L3vKxULUOTQBQ4ZD+rV6+OdxFkCLR1drFhZz1ry/axo7aZir0tVOwLXj0zkCB4wGzmhGzOOX48cyblMGfyWI4dn01ORrKCgfQroQOHu+t/jMOUCF2cw4270xY+U5Bkhhnvet/b3M5r2/eyesdeVm/by7qKut5pq5mpESaPy2BybgZzp4xj0rgMinIzmFEwhmOPGkNacuQQP13kHQkbONLT06mpqdHS6oehZz+O9PT0eBdlROvo6qZibwt7GtrY09BKVUNb8Lm+jerGNhpaO2hq66KxrZOm9k4aWzv3W8aiP6mRJE6YnMNl75vKqVNzmVecy/hBPJwmcigJGziKioooLy+nqqoq3kUZkXp2AJSBaWzrZGNlPaU769mws47Synre3NW43yBzSsQoHJNGQXYaOekpFGankZWWzJi05N735CTDgW533N95CjkzNdLvongiQy1hA0dKSop2r5OYcXfe3N3IE+sreXL9Ljbtaug9l5eVypxJOVxx5jRmTshmQk4a47PTKcxOY1xGimYfybCXsIFDZKi5Oxt21vPE+kqeWL+LrVVNmMH8aXl8bcGxwcDzpLFMyFG3kYxsChwi78Hu+lZe3lrDy1tr+NuWaspqW4gkGe+bkc+XzpzOR+ZMYHy2xoJkdFHgEBmgprZOKva1sLGynpe31vLK1hq2VjcBkJ2ezOnT81h69jEsmH0UeVmph8hNZOSKaeAws4XAz4AI8Gt3v63P+anAnUAhUAtc4u7lZjYX+AWQA3QB33f3/wrvuRv4R6AuzOZyd18Ty3pI4ujs6mbz7gbWltXxdnUj5eGzD+V7W6iNejguOy2Z+dPzuGh+MWfMyGf2pBythSQJI2aBw8wiwB3AAqAcWGlmK9y9NOqyfwPudfd7zOwc4IfApUAz8EV3f8vMJgGrzewpd98X3vfNcL9ykcPW3R3szbC2fF/vqqpvVNTR2hHMdEpLTmJybgZFuZmcMHksRbnBRjkzCsYwa2I2yVotVRJULFsc84Et7r4VwMyWA+cB0YFjNvC18PNzwKMA7v5mzwXuvtPM9hC0SvYhcgBtnV3UNXfQ3tVNZ5fT2d1NR5fT0dVNXUtH72qt28L37TXNvTu4pSYnccKkHC6aXxzs4zBlHMV5mRrEFulHLAPHZKAs6rgcOL3PNWuBCwi6sz4NZJtZvrvX9FxgZvOBVODvUfd938y+CzwLXO/ubX1/uJktAZYAFBcXv/fayLDl7jz8WgW3/qn0XUtp9CctOYlp+cG+zmcdN56p+ZmcNHkcxx2VPSQrsookgngPjn8D+A8zuxx4AaggGNMAwMwmAr8FLnP3nielbgB2EQSTZcB1wC19M3b3ZeF5SkpKtD7GKLW9pon/88h6/ralmpKpuZw/bzKpkSSSI0ZyJImUpOB9TFoy0woymZCdruckRN6jWAaOCmBK1HFRmNbL3XcStDgwszHAhT3jGGaWA/wJ+D/u/nLUPZXhxzYzu4sg+EiC6ejq5jd/e5ufPvMmKUlJ3Hr+CXxhfrGCgsgREMvAsRKYaWbTCQLGIuAL0ReYWQFQG7YmbiCYYYWZpQKPEAycP9TnnonuXmlB5/P5wPoY1kGGme5u542KOm74/RuUVtbzkdkTuOW8EzhqrJ6VEDlSYhY43L3TzJYCTxFMx73T3TeY2S3AKndfAZwF/NDMnKCr6urw9s8BHwTyw24seGfa7X1mVggYsAa4KlZ1kPh4u7qJ+17ezuode2lu66KpvZOW9uC9Z8bT+Ow0fnnJKSw8YWKcSyuSeBJ2B0AZXjq7unl20x5+9/J2/vpWNclJRsm0XMZmpJCVmkxGaoSstGQyUiLkZqbw6VOKDrkHtYi8N9oBUIalyroW/r9V5Tzw6g4q61qZNDadry84ls/Pn6KlOkSGKQUOOWI6urrZVNnAazv2snr7Xl7bsZfyvS0AfGBmAf/yqTmcc/x4PVgnMswpcEhMNbZ1smLNTlasrWBN2b7eMYoJOWmcUpzLZe+bxodnT2B6QVacSyoiA6XAIUPO3VlbXscDr+zgj+t20tzexczxY1h0WjGnTs3llKm5TBqbrqeyRUYoBQ4ZMtWNbTz+RiX3v7KDTbsayEiJcO7JE1k0v5h5U8YpUIiMEgocctjqWjp49e1aXvx7NS/9vaZ3l7sTJ4/l+58+gU+dPInsdM18EhltFDhkUFrau/j1X7fyzMbdvFFRR7dDekoSJVPz+OZHJ3HWcYXMmTQ23sUUkRhS4JAB++83q7jx0Tcoq22hZGouS8+ZyfuPzmde8TjSkiPxLp6IHCEKHHJI1Y1tfO+xUv6wZiczCrNYvuQMzpiRH+9iiUicKHDIAbk7D64q4wePb6KlvYtrPzSTr5x9tFoXIglOgUP69dbuBm58dD2vvF3L/Ol5/ODTJ3LM+DHxLpaIDAMKHPIuDa0d/OyZt7j7xW1kpSXzowtP5LOnTtFy5SLSS4FDgKBb6tE1Ffzg8U1UN7ax6LQpfPOjx5OXlRrvoonIMKPAIZTurOemFetZuW0vJ08Zx6+/WMLJU8bFu1giMkwpcCSwdeX7uOfF7TzyejnjMlPVLSUiA6LAkWDaOrv407pK7n1pO2vK9pGZGuGy90/j2g/NZFymuqVE5NAUOBLEzn0t3PfKdpa/WkZNUzszCrO4+dzZXHBqETlaFkREBiGmgcPMFgI/I9g69tfufluf81MJ9hkvBGqBS9y9PDx3GXBjeOmt7n5PmH4qcDeQATwOXOuJsI3hYWpu7+SO57bwqxfeprO7mw/PmsAX3zeNM4/J16KDInJYYhY4zCwC3AEsAMqBlWa2wt1Loy77N+Bed7/HzM4BfghcamZ5wE1ACeDA6vDevcAvgMXAKwSBYyHwRKzqMVK5O0+s38Wtj5Wys66VC+ZN5msfOZai3Mx4F01ERrhYtjjmA1vcfSuAmS0HzgOiA8ds4Gvh5+eAR8PPHwWedvfa8N6ngYVm9jyQ4+4vh+n3AuejwPEuW/Y0cNOKDfzPlhpmTczhZxfN47RpefEuloiMErEMHJOBsqjjcuD0PtesBS4g6M76NJBtZvkHuHdy+CrvJ30/ZrYEWAJQXFx82JUYSZrbO/npM29x59/eJjM1wi3nzeEL84u1FauIDKl4D45/A/gPM7sceAGoALqGImN3XwYsAygpKRn1YyDrK+r45+Wvs7Wqic+XTOFbC48jf0xavIslIqNQLANHBTAl6rgoTOvl7jsJWhyY2RjgQnffZ2YVwFl97n0+vL/oYHkmmu5u59d/28q/PrWZ/Kw07v/y6bz/mIJ4F0tERrFY9mGsBGaa2XQzSwUWASuiLzCzAjPrKcMNBDOsAJ4CPmJmuWaWC3wEeMrdK4F6MzvDgilBXwT+EMM6DGu761v54p2v8oPHN/Gh4yfwxLUfUNAQkZiLWYvD3TvNbClBEIgAd7r7BjO7BVjl7isIWhU/NDMn6Kq6Ory31sy+RxB8AG7pGSgHvsI703GfIEEHxv+8YRfXPbyO1o5ufnjBiSw6bYqm14rIEWGJ8AhESUmJr1q1Kt7FGBLuzg+f2MSyF7YyZ1IOt180j6MLtdy5iAw9M1vt7iV90+M9OC6D0N3t3PiH9dz/yg4uPWMqN35yljZVEpEjToFjhOjqdr710Doefq2cr5x1NN/86HHqmhKRuFDgGAE6urr52oNr+ePanXz1w8fyzx86RkFDROJGgWOYa+vs4p8feJ2nNuzm+o8dz1X/eHS8iyQiCU6BYxhr7ejin363muc2V3HTubO54szp8S6SiIgCx3DV3tnN4ntX8bct1fzg0yfyhdMTY9kUERn+FDiGIXfnu39Yz1/fqub/XngSnzttyqFvEhE5QrT63TB01/9sY/nKMpaefYyChogMOwocw8x/v1nFrX8q5SOzJ/C1BcfGuzgiIvtR4BhGtuxpZOn9r3HshGx+8vm5JCVpyq2IDD8KHMPEvuZ2vnzPSlIjSfz6shKy0jT8JCLDk76dhoGOrm6uvv81Kva18MDiM7S9q4gMawocw8Ctj5XyP1tq+NfPnESJtngVkWFOXVVx9ujrFdzz0nYWf2A6ny3RDCoRGf4UOOKourGNm/+4gVOKx3H9x2bFuzgiIgOiwBFHN6/YQHNbFz+68CQimkElIiOEAkec/HnDLh5bV8k15xzDzAnZ8S6OiMiAxTRwmNlCM9tsZlvM7Pp+zheb2XNm9rqZrTOzj4fpF5vZmqhXt5nNDc89H+bZc258LOsQC3UtHXznD+s5/qhs/pdWuxWRESZms6rMLALcASwAyoGVZrbC3UujLrsReNDdf2Fms4HHgWnufh9wX5jPicCj7r4m6r6L3X3E7gV72xMbqWpo41dfLCE1WY0+ERlZYvmtNR/Y4u5b3b0dWA6c1+caB3LCz2OBnf3kc1F476jw4pZqHni1jMUfmMFJRePiXRwRkUGLZeCYDJRFHZeHadFuBi4xs3KC1sY1/eTzeeCBPml3hd1U37EDbIVnZkvMbJWZraqqqjqsCgy1lvYurv/9G0zLz+R/f1jrUInIyBTvfpKLgLvdvQj4OPBbM+stk5mdDjS7+/qoey529xOBD4SvS/vL2N2XuXuJu5cUFhbGrgaD8P+e3syO2mZuu/AkMlIj8S6OiMhhiWXgqACin2grCtOiXQk8CODuLwHpQEHU+UX0aW24e0X43gDcT9AlNuytKdvHb/72NhefXswZM/LjXRwRkcMWy8CxEphpZtPNLJUgCKzoc80O4EMAZjaLIHBUhcdJwOeIGt8ws2QzKwg/pwCfBNYzAvzw8Y0UZqdx/ceOj3dRRETek5gFDnfvBJYCTwEbCWZPbTCzW8zsU+FlXwcWm9lagpbF5e7u4bkPAmXuvjUq2zTgKTNbB6whaMH8KlZ1GCpb9jTwytu1XHHmdLLTU+JdHBGR9ySmixy6++MEg97Rad+N+lwKnHmAe58HzuiT1gScOuQFjbH7XykjJWJ85tSieBdFROQ9i/fg+KjX2tHFw6+V85E5R1EwJi3exRERec8UOGLsifWV1LV0cPH84ngXRURkSChwxNj9r+xgWn4m7ztaM6lEZHRQ4IihN3c3sHLbXi6aX8wBnlMUERlxFDhi6P5XdpAaSdKguIiMKgocMdLa0cXvXyvnoyccRb4GxUVkFFHgiJE/raukvrWTL2hQXERGGQWOGLn/1R3MKMjijBl58S6KiMiQUuCIgc27Gli9XYPiIjI6DThwmFlmLAsymtz/ynZSI0lcqEFxERmFDhk4zOz9ZlYKbAqPTzazn8e8ZCNUS3sXv3+9goUnHEVeVmq8iyMiMuQG0uL4CfBRoAbA3dcSLEAo/Xhs3U4aWjv5wukaFBeR0WlAXVXuXtYnqSsGZRkV7n91B0cXZnH6dA2Ki8joNJDAUWZm7wfczFLM7BsEy6RLHzWNbby+Yx8XnFKkQXERGbUGEjiuAq4m2C+8ApgbHksfpZX1AMybMi7OJRERiZ1D7sfh7tXAxUegLCPexjBwzJqYE+eSiIjEziEDh5ndBXjfdHf/UkxKNIKV7qxn4th0cjWbSkRGsYF0VT0G/Cl8PQvkAI0DydzMFprZZjPbYmbX93O+2MyeM7PXzWydmX08TJ9mZi1mtiZ8/TLqnlPN7I0wz9ttGA0mbKxsUGtDREa9gXRVPRx9bGYPAH871H1mFgHuABYA5cBKM1sRbhfb40aCvch/YWazCbaZnRae+7u7z+0n618Ai4FXwusXAk8cqjyx1trRxZaqRhbMnhDvooiIxNThLDkyExg/gOvmA1vcfau7twPLgfP6XOMELRiAscDOg2VoZhOBHHd/2d0duBc4fzCFj5Utexrp6na1OERk1BvIGEcDwRe8he+7gOsGkPdkIPr5j3Lg9D7X3Az82cyuAbKAD0edm25mrwP1wI3u/tcwz/I+eU4+QLmXAEsAiotj/zBe6c5gYHz2JAUOERndBtJVlR3Dn38RcLe7/9jM3gf81sxOACqBYnevMbNTgUfNbM5gMnb3ZcAygJKSkv0G94daaWU9makRpuZpSS8RGd0OGDjM7JSD3ejurx0i7wpgStRxUZgW7UqCMQrc/SUzSwcK3H0P0BamrzazvwPHhvdHrxzYX55xUVpZz/FHZZOUNGzG6kVEYuJgLY4fH+ScA+ccIu+VwEwzm07w5b4I+EKfa3YAHwLuNrNZQDpQZWaFQK27d5nZDIJxla3uXmtm9WZ2BsHg+BeBfz9EOWLO3dlYWc95cyfFuygiIjF3wMDh7me/l4zdvdPMlgJPARHgTnffYGa3AKvcfQXwdeBXZvZVgmB0ubu7mX0QuMXMOoBu4Cp3rw2z/gpwN5BBMJsq7jOqyve20NDaqYFxEUkIhxzjAAjHHWYTtAgAcPd7D3Wfuz9OMGU2Ou27UZ9LgTP7ue9h4OG+6eG5VcAJAyn3kdKz1MhsBQ4RSQADmVV1E3AWQeB4HPgYwXMchwwciWJjZT1mcNxRsZxHICIyPAzkOY7PEIxD7HL3K4CTCZ65kFDpznqmF2SRmTqgBpyIyIg2kMDR6u7dQKeZ5QB7ePdsqYS3cVe9uqlEJGEcMHCY2R1m9g/Aq2Y2DvgVsBp4DXjpCJVv2Ktr6aCstkUD4yKSMA7Wt/Im8K/AJKAJeIBg3akcd193BMo2Imyq1BPjIpJYDtjicPefufv7CPYXrwHuBJ4EPm1mM49Q+Ya9jZpRJSIJ5pBjHO6+3d1/5O7zCJYIOR/YFPOSjRCllfXkZ6UyPjst3kURETkiDhk4zCzZzM41s/sIHrbbDFwQ85KNED17cAyjbUFERGLqYIPjC8zsToIVaBcTbOR0tLsvcvc/HKkCDmedXd1s3t2g8Q0RSSgHGxy/Abgf+Lq77z1C5RlRtlY30d7ZzayJevBPRBLHwdaqOtQihgmvdw+OiXoeUkQSx+HsACih0sp6UpOTmFGYFe+iiIgcMQoc78HGynqOnTCGlIh+jSKSOPSNd5jcndKdWmpERBKPAsdhqmpoo6apXUuNiEjCUeA4TBv0xLiIJCgFjsPUs9TI8QocIpJgYho4zGyhmW02sy1mdn0/54vN7Dkze93M1pnZx8P0BWa22szeCN/Pibrn+TDPNeFrfCzrcCClO+spys1gbEZKPH68iEjcxGznITOLAHcQrKhbDqw0sxXhdrE9bgQedPdfmFnPDoPTgGrgXHffGW5b+xQwOeq+i8MtZOOmtFID4yKSmGLZ4pgPbHH3re7eDiwHzutzjQM9375jgZ0A7v66u+8M0zcAGWY2bFYRbG7v5O3qJg2Mi0hCimXgmAyURR2X8+5WA8DNwCVmVk7Q2rimn3wuBF5z97aotLvCbqrvWBxWF9y8qwF37cEhIokp3oPjFwF3u3sR8HHgt2bWWyYzmwP8CPhfUfdc7O4nAh8IX5f2l094WKMAAA2TSURBVLGZLTGzVWa2qqqqakgLvWVPIwDHTdAaVSKSeGIZOCp4997kRWFatCuBBwHc/SUgHSgAMLMi4BHgi+7+954b3L0ifG8gWIRxfn8/3N2XuXuJu5cUFhYOSYV6VDUGjZ8JOelDmq+IyEgQy8CxEphpZtPNLBVYBKzoc80O4EMAZjaLIHBUhXuc/wm43t3/p+ficG+QnsCSAnwSWB/DOvSruqGdrNQIGamRI/2jRUTiLmaBw907gaUEM6I2Esye2mBmt5jZp8LLvg4sNrO1BHuaX+7uHt53DPDdPtNu04CnzGwdsIagBfOrWNXhQKob28gfM2zG6kVEjqiYTccFcPfHCQa9o9O+G/W5FDizn/tuBW49QLanDmUZD0dNUxsFY1LjXQwRkbiI9+D4iFTd0E6BWhwikqAUOA6DuqpEJJEpcAxSZ1c3tc3tFKqrSkQSlALHIO1t7sAdCrLV4hCRxKTAMUjV4TMc+VkKHCKSmBQ4BqkncGhWlYgkKgWOQappbAfUVSUiiUuBY5DeaXEocIhIYlLgGKSqxjZSI0nkpMf02UkRkWFLgWOQahrbyR+TShxWcxcRGRYUOAapurFN3VQiktAUOAYpeGpcM6pEJHEpcAxSTaPWqRKRxKbAMQjursAhIglPgWMQ6ls6ae/q1sN/IpLQFDgGoUrPcIiIKHAMRo0Ch4iIAsdgVPcuN6KuKhFJXDENHGa20Mw2m9kWM7u+n/PFZvacmb1uZuvM7ONR524I79tsZh8daJ6xpJVxRURiGDjMLALcAXwMmA1cZGaz+1x2I/Cgu88DFgE/D++dHR7PARYCPzezyADzjJmaxjaSDPKy1OIQkcQVyxbHfGCLu29193ZgOXBen2scyAk/jwV2hp/PA5a7e5u7vw1sCfMbSJ4xU9XYTl5WKpEkLTciIokrloFjMlAWdVwepkW7GbjEzMqBx4FrDnHvQPIEwMyWmNkqM1tVVVV1uHV4l+rGNnVTiUjCi/fg+EXA3e5eBHwc+K2ZDUmZ3H2Zu5e4e0lhYeFQZElNY5sGxkUk4cUycFQAU6KOi8K0aFcCDwK4+0tAOlBwkHsHkmfMVOupcRGRmAaOlcBMM5tuZqkEg90r+lyzA/gQgJnNIggcVeF1i8wszcymAzOBVweYZ8xoZVwREYjZbkTu3mlmS4GngAhwp7tvMLNbgFXuvgL4OvArM/sqwUD55e7uwAYzexAoBTqBq929C6C/PGNVh2jN7Z00t3dpZVwRSXgx3cbO3R8nGPSOTvtu1OdS4MwD3Pt94PsDyfNI6N1rXC0OEUlw8R4cHzF61qkqVOAQkQSnwDFA1Q3hU+PqqhKRBKfAMUA1TeqqEhEBBY4BU4tDRCSgwDFA1Y1t5KQnk5YciXdRRETiSoFjgKqb9PCfiAgocAxYdYMe/hMRAQWOAavWOlUiIoACx4DVNLVrZVwRERQ4BqSjq5t9zR3qqhIRQYFjQGq017iISC8FjgHQXuMiIu9Q4BiAnsBRqBaHiIgCx0BUa2VcEZFeChwD0NPiUOAQEVHgGJCaxjbSU5LITNVyIyIiChwD0LPXuJnFuygiInEX08BhZgvNbLOZbTGz6/s5/xMzWxO+3jSzfWH62VHpa8ys1czOD8/dbWZvR52bG8s6gPYaFxGJFrOtY80sAtwBLADKgZVmtiLcLhYAd/9q1PXXAPPC9OeAuWF6HrAF+HNU9t9094diVfa+qhvbmTwu/Uj9OBGRYS2WLY75wBZ33+ru7cBy4LyDXH8R8EA/6Z8BnnD35hiUcUDU4hAReUcsA8dkoCzquDxM24+ZTQWmA3/p5/Qi9g8o3zezdWFXV7/f6Ga2xMxWmdmqqqqqwZc+1N3t1GpJdRGRXsNlcHwR8JC7d0UnmtlE4ETgqajkG4DjgdOAPOC6/jJ092XuXuLuJYWFhYddsH0tHXR1OwXa+U9EBIht4KgApkQdF4Vp/emvVQHwOeARd+/oSXD3Sg+0AXcRdInFTO9yI2pxiIgAsQ0cK4GZZjbdzFIJgsOKvheZ2fFALvBSP3nsN+4RtkKwYG7s+cD6IS73u/TsNa6uKhGRQMxmVbl7p5ktJehmigB3uvsGM7sFWOXuPUFkEbDc3T36fjObRtBi+e8+Wd9nZoWAAWuAq2JVB4AqrVMlIvIuMQscAO7+OPB4n7Tv9jm++QD3bqOfwXR3P2foSnhoPUuqa2VcEZHAcBkcH7aqG9tITjLGZqTEuygiIsOCAschVDe2kT8mlaQkLTciIgIKHIdU06i9xkVEoilwHEJ1YxsF2QocIiI9FDgOIVgZVzOqRER6KHAchLtT3dhGoZ7hEBHppcBxEI1tnbR1dpOvFoeISC8FjoPQXuMiIvtT4DiIGu01LiKyHwWOg3hngUN1VYmI9FDgOIiqsKtKg+MiIu9Q4DiI6oY2zCAvSy0OEZEeChwHUdPURm5mKskR/ZpERHroG/EgqhvayVdrQ0TkXWK6rPpId2LRWKYXZsW7GCIiw4oCx0FcffYx8S6CiMiwo64qEREZlJgGDjNbaGabzWyLmV3fz/mfmNma8PWmme2LOtcVdW5FVPp0M3slzPO/wv3MRUTkCIlZ4DCzCHAH8DFgNnCRmc2Ovsbdv+ruc919LvDvwO+jTrf0nHP3T0Wl/wj4ibsfA+wFroxVHUREZH+xbHHMB7a4+1Z3bweWA+cd5PqLgAcOlqGZGXAO8FCYdA9w/hCUVUREBiiWgWMyUBZ1XB6m7cfMpgLTgb9EJaeb2Soze9nMeoJDPrDP3TsHkOeS8P5VVVVV76UeIiISZbjMqloEPOTuXVFpU929wsxmAH8xszeAuoFm6O7LgGUAJSUlPqSlFRFJYLFscVQAU6KOi8K0/iyiTzeVu1eE71uB54F5QA0wzsx6At7B8hQRkRiIZeBYCcwMZ0GlEgSHFX0vMrPjgVzgpai0XDNLCz8XAGcCpe7uwHPAZ8JLLwP+EMM6iIhIHxZ8F8coc7OPAz8FIsCd7v59M7sFWOXuK8JrbgbS3f36qPveD/wn0E0Q3H7q7r8Jz80gGGjPA14HLnH3tkOUowrYfojiFgDVg67k6JDIdYfErr/qnrgGUv+p7l7YNzGmgWMkMbNV7l4S73LEQyLXHRK7/qp7YtYd3lv99eS4iIgMigKHiIgMigLHO5bFuwBxlMh1h8Suv+qeuA67/hrjEBGRQVGLQ0REBkWBQ0REBiXhA8ehln4fbczsTjPbY2bro9LyzOxpM3srfM+NZxljxcymmNlzZlZqZhvM7NowfdTX38zSzexVM1sb1v1fwvSE2qbAzCJm9rqZPRYeJ0T9zWybmb0RblOxKkw77L/7hA4cA1n6fRS6G1jYJ+164Fl3nwk8Gx6PRp3A1919NnAGcHX43zsR6t8GnOPuJwNzgYVmdgaJt03BtcDGqONEqv/Z4TYVPc9uHPbffUIHDga/9PuI5+4vALV9ks8jWKIeRvFS9e5e6e6vhZ8bCL5AJpMA9fdAY3iYEr6cBNqmwMyKgE8Avw6PE32bhsP+u0/0wDHgpd9HuQnuXhl+3gVMiGdhjgQzm0awcOYrJEj9w26aNcAe4Gng7wxwm4JR4qfAtwiWMoJBbNMwCjjwZzNbbWZLwrTD/rsfLsuqyzDh7m5mo3qOtpmNAR4G/re71wf/8AyM5vqH2xbMNbNxwCPA8XEu0hFjZp8E9rj7ajM7K97liYN/CLepGA88bWabok8O9u8+0Vscg1n6fTTbbWYTAcL3PXEuT8yYWQpB0LjP3Xu2Kk6Y+gO4+z6CVabfR+JsU3Am8Ckz20bQJX0O8DMSpP5R21TsIfhHw3zew999ogeOAS39ngBWECxRD6N4qfqwT/s3wEZ3/39Rp0Z9/c2sMGxpYGYZwAKCMZ6E2KbA3W9w9yJ3n0bw//lf3P1iEqD+ZpZlZtk9n4GPAOt5D3/3Cf/keH9Lv8e5SDFlZg8AZxEsqbwbuAl4FHgQKCZYfv5z7t53AH3EM7N/AP4KvME7/dzfJhjnGNX1N7OTCAZAIwT/YHzQ3W85nG0KRrqwq+ob7v7JRKh/WMdHwsNk4P5wi4t8DvPvPuEDh4iIDE6id1WJiMggKXCIiMigKHCIiMigKHCIiMigKHCIiMigKHCIDAEz6wpXHu15DdlCiWY2LXo1Y5F405IjIkOjxd3nxrsQIkeCWhwiMRTug/B/w70QXjWzY8L0aWb2FzNbZ2bPmllxmD7BzB4J981Ya2bvD7OKmNmvwr00/hw+/S0SFwocIkMjo09X1eejztW5+4nAfxCsUgDw78A97n4ScB9we5h+O/Df4b4ZpwAbwvSZwB3uPgfYB1wY4/qIHJCeHBcZAmbW6O5j+knfRrCB0tZwgcVd7p5vZtXARHfvCNMr3b3AzKqAouhlL8Il4J8ON9zBzK4DUtz91tjXTGR/anGIxJ4f4PNgRK+f1IXGJyWOFDhEYu/zUe8vhZ9fJFilFeBigsUXIdjC85+gd+OlsUeqkCIDpX+1iAyNjHB3vR5PunvPlNxcM1tH0Gq4KEy7BrjLzL4JVAFXhOnXAsvM7EqClsU/AZWIDCMa4xCJoXCMo8Tdq+NdFpGhoq4qEREZFLU4RERkUNTiEBGRQVHgEBGRQVHgEBGRQVHgEBGRQVHgEBGRQfn/AbwmO1abXsMaAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5IKmk7D49_n"
      },
      "source": [
        "## Task 2: Optimize the model\n",
        "\n",
        "Experiment with the following:\n",
        "\n",
        "* number of hidden layers \n",
        "* number of nodes in each layer\n",
        "* dropout regularization rate\n",
        "\n",
        "What trends did you discover?  Can you reach at least 98% accuracy against the test set? \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ucdi6Z4aMsM"
      },
      "source": [
        "def create_model_2(my_learning_rate):\n",
        "  \"\"\"Create and compile a deep neural net.\"\"\"\n",
        "  \n",
        "  # All models in this course are sequential.\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  # The features are stored in a two-dimensional 28X28 array. \n",
        "  # Flatten that two-dimensional array into a a one-dimensional \n",
        "  # 784-element array.\n",
        "  model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
        "\n",
        "  # Define the first hidden layer.   \n",
        "  model.add(tf.keras.layers.Dense(units=256, activation='relu'))\n",
        "  \n",
        "  # Define a dropout regularization layer. \n",
        "  model.add(tf.keras.layers.Dropout(rate=0.4))\n",
        "\n",
        "  # Define the output layer. The units parameter is set to 10 because\n",
        "  # the model must choose among 10 possible output values (representing\n",
        "  # the digits from 0 to 9, inclusive).\n",
        "  #\n",
        "  # Don't change this layer.\n",
        "  model.add(tf.keras.layers.Dense(units=10, activation='softmax'))     \n",
        "                           \n",
        "  # Construct the layers into a model that TensorFlow can execute.  \n",
        "  # Notice that the loss function for multi-class classification\n",
        "  # is different than the loss function for binary classification.  \n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(lr=my_learning_rate),\n",
        "                loss=\"sparse_categorical_crossentropy\",\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  return model    "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eTyp3-tmaX7K",
        "outputId": "c4d607ca-eba0-4c91-b26f-cb7a00f909ac"
      },
      "source": [
        "# The following variables are the hyperparameters.\n",
        "learning_rate = 0.003\n",
        "epochs = 50\n",
        "batch_size = 4000\n",
        "validation_split = 0.2\n",
        "\n",
        "# Establish the model's topography.\n",
        "my_model = create_model_2(learning_rate)\n",
        "\n",
        "# Train the model on the normalized training set.\n",
        "epochs, hist = train_model(my_model, x_train_normalized, y_train, \n",
        "                           epochs, batch_size, validation_split)\n",
        "\n",
        "# Plot a graph of the metric vs. epochs.\n",
        "list_of_metrics_to_plot = ['accuracy']\n",
        "plot_curve(epochs, hist, list_of_metrics_to_plot)\n",
        "\n",
        "# Evaluate against the test set.\n",
        "print(\"\\n Evaluate the new model against the test set:\")\n",
        "my_model.evaluate(x=x_test_normalized, y=y_test, batch_size=batch_size)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 1s 96ms/step - loss: 1.0604 - accuracy: 0.6764 - val_loss: 0.3778 - val_accuracy: 0.8894\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 1s 83ms/step - loss: 0.4223 - accuracy: 0.8715 - val_loss: 0.2818 - val_accuracy: 0.9197\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 1s 83ms/step - loss: 0.3177 - accuracy: 0.9073 - val_loss: 0.2371 - val_accuracy: 0.9334\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 1s 83ms/step - loss: 0.2651 - accuracy: 0.9235 - val_loss: 0.2033 - val_accuracy: 0.9423\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 1s 82ms/step - loss: 0.2294 - accuracy: 0.9322 - val_loss: 0.1800 - val_accuracy: 0.9497\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 1s 83ms/step - loss: 0.2033 - accuracy: 0.9416 - val_loss: 0.1637 - val_accuracy: 0.9538\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 1s 82ms/step - loss: 0.1831 - accuracy: 0.9476 - val_loss: 0.1520 - val_accuracy: 0.9561\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.1678 - accuracy: 0.9510 - val_loss: 0.1412 - val_accuracy: 0.9601\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 1s 83ms/step - loss: 0.1579 - accuracy: 0.9536 - val_loss: 0.1317 - val_accuracy: 0.9624\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 1s 82ms/step - loss: 0.1461 - accuracy: 0.9580 - val_loss: 0.1269 - val_accuracy: 0.9632\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 1s 82ms/step - loss: 0.1351 - accuracy: 0.9611 - val_loss: 0.1196 - val_accuracy: 0.9649\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 1s 83ms/step - loss: 0.1246 - accuracy: 0.9630 - val_loss: 0.1151 - val_accuracy: 0.9662\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 1s 82ms/step - loss: 0.1197 - accuracy: 0.9640 - val_loss: 0.1111 - val_accuracy: 0.9668\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.1124 - accuracy: 0.9672 - val_loss: 0.1056 - val_accuracy: 0.9689\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 1s 83ms/step - loss: 0.1056 - accuracy: 0.9690 - val_loss: 0.1016 - val_accuracy: 0.9693\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 1s 82ms/step - loss: 0.0976 - accuracy: 0.9715 - val_loss: 0.1004 - val_accuracy: 0.9698\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 1s 83ms/step - loss: 0.0950 - accuracy: 0.9725 - val_loss: 0.0968 - val_accuracy: 0.9703\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.0909 - accuracy: 0.9731 - val_loss: 0.0963 - val_accuracy: 0.9701\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.0881 - accuracy: 0.9745 - val_loss: 0.0925 - val_accuracy: 0.9727\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.0825 - accuracy: 0.9759 - val_loss: 0.0905 - val_accuracy: 0.9720\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 1s 83ms/step - loss: 0.0783 - accuracy: 0.9770 - val_loss: 0.0883 - val_accuracy: 0.9738\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 1s 82ms/step - loss: 0.0770 - accuracy: 0.9766 - val_loss: 0.0873 - val_accuracy: 0.9745\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 1s 83ms/step - loss: 0.0722 - accuracy: 0.9794 - val_loss: 0.0858 - val_accuracy: 0.9743\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 1s 83ms/step - loss: 0.0680 - accuracy: 0.9798 - val_loss: 0.0839 - val_accuracy: 0.9745\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 1s 83ms/step - loss: 0.0670 - accuracy: 0.9797 - val_loss: 0.0840 - val_accuracy: 0.9747\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 1s 83ms/step - loss: 0.0620 - accuracy: 0.9818 - val_loss: 0.0822 - val_accuracy: 0.9756\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 1s 83ms/step - loss: 0.0620 - accuracy: 0.9816 - val_loss: 0.0810 - val_accuracy: 0.9763\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 1s 83ms/step - loss: 0.0580 - accuracy: 0.9832 - val_loss: 0.0819 - val_accuracy: 0.9759\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.0600 - accuracy: 0.9824 - val_loss: 0.0786 - val_accuracy: 0.9772\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 1s 83ms/step - loss: 0.0536 - accuracy: 0.9845 - val_loss: 0.0787 - val_accuracy: 0.9768\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 1s 83ms/step - loss: 0.0535 - accuracy: 0.9839 - val_loss: 0.0781 - val_accuracy: 0.9765\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 1s 82ms/step - loss: 0.0517 - accuracy: 0.9846 - val_loss: 0.0792 - val_accuracy: 0.9766\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.0505 - accuracy: 0.9860 - val_loss: 0.0769 - val_accuracy: 0.9770\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 1s 83ms/step - loss: 0.0474 - accuracy: 0.9864 - val_loss: 0.0778 - val_accuracy: 0.9779\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.0465 - accuracy: 0.9864 - val_loss: 0.0766 - val_accuracy: 0.9777\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.0450 - accuracy: 0.9870 - val_loss: 0.0759 - val_accuracy: 0.9783\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 1s 83ms/step - loss: 0.0431 - accuracy: 0.9872 - val_loss: 0.0751 - val_accuracy: 0.9779\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 1s 83ms/step - loss: 0.0418 - accuracy: 0.9872 - val_loss: 0.0746 - val_accuracy: 0.9783\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.0412 - accuracy: 0.9883 - val_loss: 0.0730 - val_accuracy: 0.9781\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 1s 83ms/step - loss: 0.0398 - accuracy: 0.9881 - val_loss: 0.0743 - val_accuracy: 0.9787\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 1s 83ms/step - loss: 0.0370 - accuracy: 0.9887 - val_loss: 0.0738 - val_accuracy: 0.9786\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 1s 83ms/step - loss: 0.0368 - accuracy: 0.9892 - val_loss: 0.0742 - val_accuracy: 0.9777\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.0377 - accuracy: 0.9887 - val_loss: 0.0743 - val_accuracy: 0.9781\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 1s 83ms/step - loss: 0.0346 - accuracy: 0.9892 - val_loss: 0.0729 - val_accuracy: 0.9787\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.0353 - accuracy: 0.9893 - val_loss: 0.0723 - val_accuracy: 0.9780\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 1s 82ms/step - loss: 0.0338 - accuracy: 0.9898 - val_loss: 0.0732 - val_accuracy: 0.9796\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.0328 - accuracy: 0.9900 - val_loss: 0.0724 - val_accuracy: 0.9792\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 1s 85ms/step - loss: 0.0316 - accuracy: 0.9908 - val_loss: 0.0734 - val_accuracy: 0.9785\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 1s 84ms/step - loss: 0.0319 - accuracy: 0.9904 - val_loss: 0.0731 - val_accuracy: 0.9791\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 1s 86ms/step - loss: 0.0298 - accuracy: 0.9909 - val_loss: 0.0727 - val_accuracy: 0.9799\n",
            "\n",
            " Evaluate the new model against the test set:\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0671 - accuracy: 0.9787\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06706134974956512, 0.9786999821662903]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYG5qXpP5a9n"
      },
      "source": [
        "#@title Double-click to view some possible answers.\n",
        "\n",
        "# It would take much too long to experiment \n",
        "# fully with topography and dropout regularization \n",
        "# rate. In the real world, you would\n",
        "# also experiment with learning rate, batch size, \n",
        "# and number of epochs.  Since you only have a \n",
        "# few minutes, searching for trends can be helpful.\n",
        "# Here is what we discovered:\n",
        "#   * Adding more nodes (at least until 256 nodes) \n",
        "#     to the first hidden layer improved accuracy.\n",
        "#   * Adding a second hidden layer generally \n",
        "#     improved accuracy.\n",
        "#   * When the model contains a lot of nodes, \n",
        "#     the model overfits unless the dropout rate \n",
        "#     is at least 0.5. \n",
        "\n",
        "# We reached 98% test accuracy with the \n",
        "# following configuration:\n",
        "#   * One hidden layer of 256 nodes; no second \n",
        "#     hidden layer.\n",
        "#   * dropout regularization rate of 0.4\n",
        "\n",
        "# We reached 98.2% test accuracy with the \n",
        "# following configuration:\n",
        "#   * First hidden layer of 256 nodes; \n",
        "#     second hidden layer of 128 nodes.\n",
        "#   * dropout regularization rate of 0.2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYKzRFGgbqYU"
      },
      "source": [
        "def create_model_3(my_learning_rate):\n",
        "  \"\"\"Create and compile a deep neural net.\"\"\"\n",
        "  \n",
        "  # All models in this course are sequential.\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  # The features are stored in a two-dimensional 28X28 array. \n",
        "  # Flatten that two-dimensional array into a a one-dimensional \n",
        "  # 784-element array.\n",
        "  model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
        "\n",
        "  # Define the first hidden layer.   \n",
        "  model.add(tf.keras.layers.Dense(units=256, activation='relu'))\n",
        "  \n",
        "  # Define a dropout regularization layer. \n",
        "  model.add(tf.keras.layers.Dropout(rate=0.4))\n",
        "\n",
        "    # Define the first hidden layer.   \n",
        "  model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "  \n",
        "  # Define a dropout regularization layer. \n",
        "  model.add(tf.keras.layers.Dropout(rate=0.4))\n",
        "\n",
        "  # Define the output layer. The units parameter is set to 10 because\n",
        "  # the model must choose among 10 possible output values (representing\n",
        "  # the digits from 0 to 9, inclusive).\n",
        "  #\n",
        "  # Don't change this layer.\n",
        "  model.add(tf.keras.layers.Dense(units=10, activation='softmax'))     \n",
        "                           \n",
        "  # Construct the layers into a model that TensorFlow can execute.  \n",
        "  # Notice that the loss function for multi-class classification\n",
        "  # is different than the loss function for binary classification.  \n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(lr=my_learning_rate),\n",
        "                loss=\"sparse_categorical_crossentropy\",\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  return model    "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pAFIjEOobnrT",
        "outputId": "f7581a42-6b9f-4f50-cd8f-c6a38c5c5be8"
      },
      "source": [
        "# The following variables are the hyperparameters.\n",
        "learning_rate = 0.003\n",
        "epochs = 50\n",
        "batch_size = 4000\n",
        "validation_split = 0.2\n",
        "\n",
        "# Establish the model's topography.\n",
        "my_model = create_model_3(learning_rate)\n",
        "\n",
        "# Train the model on the normalized training set.\n",
        "epochs, hist = train_model(my_model, x_train_normalized, y_train, \n",
        "                           epochs, batch_size, validation_split)\n",
        "\n",
        "# Plot a graph of the metric vs. epochs.\n",
        "list_of_metrics_to_plot = ['accuracy']\n",
        "plot_curve(epochs, hist, list_of_metrics_to_plot)\n",
        "\n",
        "# Evaluate against the test set.\n",
        "print(\"\\n Evaluate the new model against the test set:\")\n",
        "my_model.evaluate(x=x_test_normalized, y=y_test, batch_size=batch_size)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 2s 115ms/step - loss: 1.2230 - accuracy: 0.6010 - val_loss: 0.3779 - val_accuracy: 0.8927\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 1s 103ms/step - loss: 0.4656 - accuracy: 0.8592 - val_loss: 0.2548 - val_accuracy: 0.9251\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 1s 103ms/step - loss: 0.3300 - accuracy: 0.9036 - val_loss: 0.2009 - val_accuracy: 0.9402\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 1s 103ms/step - loss: 0.2645 - accuracy: 0.9227 - val_loss: 0.1680 - val_accuracy: 0.9503\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.2215 - accuracy: 0.9358 - val_loss: 0.1459 - val_accuracy: 0.9571\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.1944 - accuracy: 0.9430 - val_loss: 0.1324 - val_accuracy: 0.9606\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 1s 102ms/step - loss: 0.1740 - accuracy: 0.9484 - val_loss: 0.1228 - val_accuracy: 0.9632\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 1s 103ms/step - loss: 0.1590 - accuracy: 0.9531 - val_loss: 0.1145 - val_accuracy: 0.9658\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 1s 102ms/step - loss: 0.1450 - accuracy: 0.9568 - val_loss: 0.1083 - val_accuracy: 0.9682\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 1s 102ms/step - loss: 0.1336 - accuracy: 0.9602 - val_loss: 0.1055 - val_accuracy: 0.9697\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 1s 103ms/step - loss: 0.1239 - accuracy: 0.9634 - val_loss: 0.0996 - val_accuracy: 0.9705\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 1s 102ms/step - loss: 0.1143 - accuracy: 0.9665 - val_loss: 0.0968 - val_accuracy: 0.9718\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 1s 103ms/step - loss: 0.1047 - accuracy: 0.9687 - val_loss: 0.0925 - val_accuracy: 0.9735\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 1s 103ms/step - loss: 0.1033 - accuracy: 0.9689 - val_loss: 0.0889 - val_accuracy: 0.9738\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 1s 102ms/step - loss: 0.0969 - accuracy: 0.9716 - val_loss: 0.0893 - val_accuracy: 0.9746\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.0910 - accuracy: 0.9722 - val_loss: 0.0904 - val_accuracy: 0.9735\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 1s 103ms/step - loss: 0.0855 - accuracy: 0.9743 - val_loss: 0.0870 - val_accuracy: 0.9743\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 1s 102ms/step - loss: 0.0810 - accuracy: 0.9750 - val_loss: 0.0824 - val_accuracy: 0.9751\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 1s 102ms/step - loss: 0.0753 - accuracy: 0.9762 - val_loss: 0.0832 - val_accuracy: 0.9755\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.0742 - accuracy: 0.9774 - val_loss: 0.0807 - val_accuracy: 0.9765\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 1s 105ms/step - loss: 0.0681 - accuracy: 0.9790 - val_loss: 0.0838 - val_accuracy: 0.9767\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 1s 103ms/step - loss: 0.0673 - accuracy: 0.9793 - val_loss: 0.0809 - val_accuracy: 0.9765\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 1s 102ms/step - loss: 0.0652 - accuracy: 0.9795 - val_loss: 0.0826 - val_accuracy: 0.9761\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 1s 102ms/step - loss: 0.0605 - accuracy: 0.9811 - val_loss: 0.0829 - val_accuracy: 0.9755\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 1s 103ms/step - loss: 0.0611 - accuracy: 0.9805 - val_loss: 0.0794 - val_accuracy: 0.9770\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 1s 103ms/step - loss: 0.0568 - accuracy: 0.9822 - val_loss: 0.0809 - val_accuracy: 0.9766\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.0535 - accuracy: 0.9831 - val_loss: 0.0796 - val_accuracy: 0.9779\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 1s 103ms/step - loss: 0.0525 - accuracy: 0.9833 - val_loss: 0.0817 - val_accuracy: 0.9781\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.0516 - accuracy: 0.9833 - val_loss: 0.0821 - val_accuracy: 0.9766\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.0510 - accuracy: 0.9842 - val_loss: 0.0798 - val_accuracy: 0.9786\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 1s 102ms/step - loss: 0.0501 - accuracy: 0.9843 - val_loss: 0.0760 - val_accuracy: 0.9802\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 1s 104ms/step - loss: 0.0460 - accuracy: 0.9856 - val_loss: 0.0791 - val_accuracy: 0.9790\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 1s 101ms/step - loss: 0.0449 - accuracy: 0.9848 - val_loss: 0.0820 - val_accuracy: 0.9776\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 1s 101ms/step - loss: 0.0438 - accuracy: 0.9857 - val_loss: 0.0789 - val_accuracy: 0.9781\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 1s 103ms/step - loss: 0.0419 - accuracy: 0.9864 - val_loss: 0.0805 - val_accuracy: 0.9778\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 1s 103ms/step - loss: 0.0412 - accuracy: 0.9867 - val_loss: 0.0802 - val_accuracy: 0.9792\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 1s 103ms/step - loss: 0.0385 - accuracy: 0.9877 - val_loss: 0.0811 - val_accuracy: 0.9800\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 1s 103ms/step - loss: 0.0380 - accuracy: 0.9879 - val_loss: 0.0803 - val_accuracy: 0.9798\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 1s 102ms/step - loss: 0.0384 - accuracy: 0.9871 - val_loss: 0.0808 - val_accuracy: 0.9797\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 1s 103ms/step - loss: 0.0371 - accuracy: 0.9877 - val_loss: 0.0834 - val_accuracy: 0.9796\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 1s 102ms/step - loss: 0.0350 - accuracy: 0.9888 - val_loss: 0.0807 - val_accuracy: 0.9798\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 1s 102ms/step - loss: 0.0350 - accuracy: 0.9887 - val_loss: 0.0839 - val_accuracy: 0.9783\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 1s 102ms/step - loss: 0.0338 - accuracy: 0.9890 - val_loss: 0.0809 - val_accuracy: 0.9794\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 1s 102ms/step - loss: 0.0336 - accuracy: 0.9890 - val_loss: 0.0815 - val_accuracy: 0.9801\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 1s 103ms/step - loss: 0.0336 - accuracy: 0.9886 - val_loss: 0.0815 - val_accuracy: 0.9793\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 1s 103ms/step - loss: 0.0320 - accuracy: 0.9892 - val_loss: 0.0807 - val_accuracy: 0.9793\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 1s 102ms/step - loss: 0.0322 - accuracy: 0.9899 - val_loss: 0.0843 - val_accuracy: 0.9793\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 1s 103ms/step - loss: 0.0304 - accuracy: 0.9905 - val_loss: 0.0824 - val_accuracy: 0.9795\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 1s 102ms/step - loss: 0.0305 - accuracy: 0.9895 - val_loss: 0.0822 - val_accuracy: 0.9789\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 1s 102ms/step - loss: 0.0276 - accuracy: 0.9912 - val_loss: 0.0860 - val_accuracy: 0.9797\n",
            "\n",
            " Evaluate the new model against the test set:\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0766 - accuracy: 0.9821\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.076572947204113, 0.9821000099182129]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}